---
title: "MiniMind: сверхлёгкая открытая серия языковых моделей с обучением за 2 часа и 3 юаня"
description: "Проект MiniMind предлагает полностью открытый исходный код для обучения компактных языковых моделей с минимальными затратами времени и средств."
heroImage: "/imgs/2025/10/15-jingyaogong-minimind.webp"
pubDate: "2025-10-15"
github: "https://github.com/jingyaogong/minimind"
---

<!-- [0, 64] -->

# MiniMind: сверхлёгкая открытая серия языковых моделей с обучением за 2 часа и 3 юаня

Проект [MiniMind](https://github.com/jingyaogong/minimind) — уникальная серия сверхлёгких языковых моделей, разработанных с акцентом на минимальные ресурсы. Ключевая цель — сделать LLM-технологии доступными каждому с порогом входа буквально в несколько часов и стоимостью аренды GPU в 3 юаня (~0.5$).

MiniMind отвечает на запрос широкого круга пользователей и исследователей, у которых нет доступа к сотням GPU и гигабайтам оперативной памяти для больших моделей типа GPT-3. Модель минимальна — от 25.8M параметров, что в 7000 раз меньше GPT-3.


## Основные особенности MiniMind

- **Экономичное обучение**: полноценная тренировка мини-модели на GPU NVIDIA 3090 за 2 часа с затратами около 3 юаней.
- **Свободный доступ ко всему стеку**: от токенизации, очистки данных, предобучения, различных видов дообучения (SFT, LoRA, DPO), до RLHF и модели обучения с передачей знаний (distillation).
- **Лёгкость**: самая маленькая версия занимает ~26M параметров, что позволяет работать на обычных GPU и быстро экспериментировать.
- **Без «черных ящиков»**: код написан полностью с нуля на PyTorch, без зависимостей от высокоуровневых абстракций, позволяя глубоко понять устройство LLM.
- **Расширяемость**: реализация позволяет строить как плотные модели (dense), так и гибридные с модулем Mixture of Experts (MoE), включая визуальные мульти-модальные версии MiniMind-V.
- **Инфраструктурная совместимость**: поддержка популярных экосистем llama.cpp, vllm, ollama и интеграция с OpenAI-API протоколом.
- **Сопутствующие инструменты**: простой чат-интерфейс на Streamlit, инструменты предобработки и конвертации моделей.


## Задачи проекта

MiniMind создавался как образовательный и исследовательский инструмент, разрушающий типичные барьеры входа к LLM:

- **Обучение с нуля** на малом бюджете, без необходимости суперкомпьютеров.
- Исследование **структур трансформеров** и алгоритмов современного обучения (LoRA, DPO, RLHF) «под капотом».
- Возможность формировать и дообучать модели под **свои данные** для узкоспециализированных задач (медицина, чатботы и т.п.).
- Демонстрация жизнеспособности очень маленьких моделей для **основных задач NLP** и диалога.
- Предоставление полностью открытых, **высококачественных датасетов** для этапов предобучения и дообучения.


## Архитектура и модели

- Используется **Decoder-Only трансформер** с pre-normalization (RMSNorm), активацией SwiGLU, и позиционными эмбеддингами типа RoPE.
- Модель MiniMind2-small имеет около 26M параметров, 8 слоёв, d_model = 512, словарь из 6400 токенов.
- Более крупные варианты включают MoE-модель с 145M параметров и увеличенную версию MiniMind2 с 104M параметров и более глубокой архитектурой (16 слоёв).
- Все ключевые части адаптированы и написаны с нуля — от токенизатора до LoRA и DPO, включая активный load balancing в MoE.
  

## Основные этапы обучения

1. **Предобучение (Pretrain)** — обучение предсказанию следующего токена на высококачественных больших корпусах (~1.6GB).
2. **Супервизированное дообучение (SFT)** — обучение на диалоговых данных для навыков общения, с сокращёнными длинами сессий до 512 токенов.
3. **LoRA (Low-Rank Adaptation)** — параметрически эффективная адаптация под новые задачи, с низкими требованиями к ресурсам.
4. **RLHF (Reinforcement Learning from Human Feedback) с DPO** — оптимизация поведения модели под человеческие предпочтения без использования наградных моделей, что облегчает и стабилизирует обучение.
5. **Knowledge Distillation (蒸馏)** — обучение маленьких моделей на мягких ответах больших, для повышения производительности при малых размерах модели.
6. **Reasoning model (推理模型)** — реализация моделей с улучшенной способностью рассуждать и объяснять шаги вывода (R1蒸馏).


## Примеры применения

- **Быстрые эксперименты** с LLM от обучения до inference всего за пару часов.
- Создание **персонализированных чатботов** с учётом специфического доменного знания (например, медицинские консультанты).
- Исследования и преподавание **основ LLM**, раскрывая механизм работы трансформеров без посредников.
- **Мульти-модальные проекты** с сочетанием текстов и изображений в MiniMind-V.
- Интеграция в существующие UI через OpenAI-совместимый API.
- Лёгкий старт для энтузиастов и исследователей без дорогостоящего железа, при доступе к 3090 или аналогичной GPU.


## Сравнение и качество модели

- MiniMind маленькая (26M params) показывает способность адекватно вести диалог и отвечать на вопросы.
- Модель с RLHF менее быстра и точна, но более «вежлива» и соответствует протоколам общения.
- На общих бенчмарках (C-Eval, C-MMLU, etc.) mini модели показывают результат на уровне ~25% точности, что сопоставимо с аналогичной низкопараметрической конкуренцией.
- Стратегия «глубокого и узкого» трансформера (больше слоёв, меньше размерность) оказывается более удачной для маленьких моделей.
  

## Заключение

MiniMind — пример того, что разработка и обучение языковой модели высокого качества и малого размера возможна на доступных ресурсах. Это не рекламный лозунг — 2 часа, 3 юаня — реально. Проект ориентирован на людей, желающих понять внутренние механизмы LLM, создать собственную модель и быстро проверить идеи без вложений в огромные кластеры.
