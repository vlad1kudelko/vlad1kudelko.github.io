+++
lang = "ru"
title = "Archon: платформа для управления знаниями и задачами с интеграцией ИИ"
description = "Archon – это микросервисный MCP-сервер для создания, управления и совместного использования базы знаний, контекста и задач проектов с помощью ИИ-помощников."
template = "posts"
thumb = "/imgs/2025/10/14-coleam00-Archon.webp"
publication_date = "2025-10-14"
github = "https://github.com/coleam00/Archon"
+++

<!-- [0, 97] > [0, 73] -->

# Archon: когда ваш AI-ассистент наконец-то понимает ваш проект

Помните ощущение, когда объясняешь Claude или ChatGPT специфику своего проекта в десятый раз, и он снова предлагает решение из учебника? Вот буквально вчера потратил полчаса, описывая архитектуру микросервисов, только чтобы получить в ответ "давай сделаем монолит на Express". Боль знакомая, правда?

Проблема не в том, что AI плохой. Проблема в том, что у него амнезия длиной в один запрос. Он не помнит вашу документацию, не знает историю проекта, понятия не имеет о том техническом долге, который вы аккуратно задокументировали три месяца назад. И именно это пытается решить Archon — платформа, которая даёт вашему AI постоянную память.

## Командный центр для ваших AI-помощников

Представьте себе центральный сервер, который хранит всё: документацию проекта, примеры кода, архитектурные решения, даже те самые важные комментарии из Confluence, которые все читали, но никто не помнит. Теперь представьте, что любой AI-ассистент может обратиться к этому серверу и получить контекст. Не абстрактные знания из интернета, а именно ваш контекст.

Это и есть Archon. По сути, это микросервисная платформа, которая выступает прослойкой между вашими инструментами разработки и AI. Работает через Model Context Protocol — относительно свежий стандарт от Anthropic, который позволяет разным AI-ассистентам (Claude Code, Cursor и другим) общаться с внешними источниками данных единообразно.

Архитектура довольно классическая для современных продуктов: React с Vite на фронте, FastAPI на бэкенде, отдельный MCP-сервер для интеграций, плюс модуль AI-агента. Всё общается через HTTP и WebSocket, что даёт возможность масштабировать компоненты независимо. База данных — Supabase с PostgreSQL и расширением PGVector для векторного поиска. Если вы хоть раз настраивали RAG-систему, поймёте, о чём речь.

## Знания, которые не теряются

Самая интересная часть Archon — это работа с knowledge base. Платформа умеет автоматически собирать информацию откуда угодно. Нужна документация с сайта? Запускаете краулер, и он пройдётся по всем страницам, соберёт контент, найдёт примеры кода. Есть внутренние PDF с архитектурными диаграммами? Загружаете, и система автоматически распознает структуру, извлечёт код, если он там есть.

Но фишка не в том, что всё это можно загрузить — это умеют многие. Фишка в семантическом поиске. Когда ваш AI спрашивает "как мы реализовали аутентификацию?", Archon не ищет по ключевым словам. Он понимает смысл вопроса, находит релевантные фрагменты в документации, примеры кода, даже обсуждения в задачах. И передаёт это всё AI как контекст.

Я тестировал на проекте с микросервисами — загрузил swagger-документацию всех сервисов, архитектурные записи, несколько README. Разница ощутимая. Claude перестал предлагать создать новый эндпоинт для функции, которая уже существует в другом сервисе. Начал учитывать наши соглашения по именованию. Стал, можно сказать, членом команды.

## Проекты, которые планируют себя сами

Вторая большая штука в Archon — это управление задачами, но не в духе Jira (слава богу). Здесь идея в том, чтобы AI помогал разбивать проекты на задачи, генерировать требования, отслеживать прогресс. Звучит немного футуристично, но работает проще, чем кажется.

Создаёте проект, описываете в свободной форме что нужно сделать, и AI предлагает декомпозицию. Понятно, что это не волшебная палочка — результат нужно проверять и корректировать. Но как отправная точка для планирования спринта работает неплохо. Особенно если ваша knowledge base уже содержит примеры похожих задач из прошлого.

Есть иерархия: проекты, фичи, задачи. Можно тегировать, фильтровать, отслеживать статусы в реальном времени. Ничего революционного, но интеграция с AI-контекстом делает работу более связной. Обсуждаете задачу с Claude в редакторе — он видит её описание, связанные документы, историю изменений.

## Реальность использования

Будем честны: проект в бета-версии, и это чувствуется. Документация местами неполная, некоторые фичи работают с оговорками. Setup требует времени — Docker, Node.js, настройка Supabase, ключи API. Не просто "npm install и поехали".

Но если у вас есть пара часов на поднятие инфраструктуры, результат того стоит. Особенно для команд, которые активно используют AI в разработке. Когда весь контекст проекта доступен любому разработчику через единую точку входа, это меняет динамику работы. Новички быстрее вкатываются, потому что могут спрашивать AI, который знает специфику вашего кода. Архитектурные решения не теряются в Notion или Confluence, а становятся частью рабочего процесса.

Ещё момент: Archon работает с разными моделями — OpenAI, Google Gemini, Ollama. То есть вы не привязаны к одному провайдеру. Можете экспериментировать, выбирать оптимальное соотношение цены и качества для разных задач.

## Что дальше?

Честно говоря, сложно предсказать, станет ли именно Archon стандартом де-факто для AI-интеграций в разработке. Рынок молодой, конкуренция растёт, крупные игроки наверняка готовят свои решения. Но сама идея — централизованный контекст для AI-ассистентов — кажется неизбежной.

Мы движемся к миру, где AI — не отдельный инструмент, который ты запускаешь время от времени, а постоянный участник процесса. И для этого ему нужна память. Настоящая, долгосрочная, структурированная память о вашем проекте, команде, решениях.

Archon — это один из первых серьёзных шагов в эту сторону. Со всеми его шероховатостями и недоделками, он показывает, как может выглядеть следующее поколение DevTools. И даже если вы не готовы деплоить его прямо сейчас, идеи, заложенные в проекте, стоит держать в голове. Потому что рано или поздно что-то подобное станет нормой.

А пока — это open source проект, в который можно заглянуть, поковыряться, может быть, даже поконтрибьютить. В конце концов, лучший способ понять будущее разработки — это попробовать его построить.
